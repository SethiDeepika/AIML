{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55864a8",
   "metadata": {
    "_cell_guid": "7ff76603-0955-461b-9190-7afac0bfabff",
    "_uuid": "9336de26-2683-4613-b96d-802f28dfa954",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-05T23:24:35.906745Z",
     "iopub.status.busy": "2026-01-05T23:24:35.906396Z",
     "iopub.status.idle": "2026-01-06T00:00:25.574562Z",
     "shell.execute_reply": "2026-01-06T00:00:25.573502Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2149.673491,
     "end_time": "2026-01-06T00:00:25.576433",
     "exception": false,
     "start_time": "2026-01-05T23:24:35.902942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DUAL-MIXUP ENSEMBLE (ResNet34 + DenseNet121) on cuda...\n",
      "\n",
      "--- Training resnet34 with MixUp ---\n",
      "Fold 1/5\n",
      "Loaded resnet34 weights.\n",
      "  Best Loss: 0.0270\n",
      "Fold 2/5\n",
      "Loaded resnet34 weights.\n",
      "  Best Loss: 0.0173\n",
      "Fold 3/5\n",
      "Loaded resnet34 weights.\n",
      "  Best Loss: 0.0183\n",
      "Fold 4/5\n",
      "Loaded resnet34 weights.\n",
      "  Best Loss: 0.0197\n",
      "Fold 5/5\n",
      "Loaded resnet34 weights.\n",
      "  Best Loss: 0.0230\n",
      "\n",
      "--- Training densenet121 with MixUp ---\n",
      "Fold 1/5\n",
      "Loaded densenet121 weights.\n",
      "  Best Loss: 0.0422\n",
      "Fold 2/5\n",
      "Loaded densenet121 weights.\n",
      "  Best Loss: 0.0337\n",
      "Fold 3/5\n",
      "Loaded densenet121 weights.\n",
      "  Best Loss: 0.0322\n",
      "Fold 4/5\n",
      "Loaded densenet121 weights.\n",
      "  Best Loss: 0.0278\n",
      "Fold 5/5\n",
      "Loaded densenet121 weights.\n",
      "  Best Loss: 0.0333\n",
      "\n",
      "Starting Ensemble Inference...\n",
      "Predicting resnet34 Fold 1...\n",
      "Loaded resnet34 weights.\n",
      "Predicting resnet34 Fold 2...\n",
      "Loaded resnet34 weights.\n",
      "Predicting resnet34 Fold 3...\n",
      "Loaded resnet34 weights.\n",
      "Predicting resnet34 Fold 4...\n",
      "Loaded resnet34 weights.\n",
      "Predicting resnet34 Fold 5...\n",
      "Loaded resnet34 weights.\n",
      "Predicting densenet121 Fold 1...\n",
      "Loaded densenet121 weights.\n",
      "Predicting densenet121 Fold 2...\n",
      "Loaded densenet121 weights.\n",
      "Predicting densenet121 Fold 3...\n",
      "Loaded densenet121 weights.\n",
      "Predicting densenet121 Fold 4...\n",
      "Loaded densenet121 weights.\n",
      "Predicting densenet121 Fold 5...\n",
      "Loaded densenet121 weights.\n",
      "Dual-MixUp Ensemble Submission Ready.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE = 320     # The winning resolution\n",
    "BATCH_SIZE = 12    # Reduced slightly to fit 2 heavy models\n",
    "EPOCHS = 15        # MixUp needs time to converge\n",
    "LEARNING_RATE = 2e-4\n",
    "N_FOLDS = 5\n",
    "IMAGE_DIR = Path(\"/kaggle/input/csiro-biomass\")\n",
    "TARGET_COLS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "print(f\"Running DUAL-MIXUP ENSEMBLE (ResNet34 + DenseNet121) on {DEVICE}...\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 4-CHANNEL DATASET\n",
    "# ==========================================\n",
    "class Biomass4ChannelDataset(Dataset):\n",
    "    def __init__(self, df, target_cols=None, is_test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.target_cols = target_cols\n",
    "        self.is_test = is_test\n",
    "        self.root_dir = IMAGE_DIR\n",
    "        self.mean = torch.tensor([0.485, 0.456, 0.406, 0.5]).view(4,1,1)\n",
    "        self.std = torch.tensor([0.229, 0.224, 0.225, 0.5]).view(4,1,1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rel_path = self.df.loc[idx, \"image_path\"]\n",
    "        img_path = self.root_dir / rel_path\n",
    "        try:\n",
    "            pil_img = Image.open(img_path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
    "            img = np.array(pil_img).astype(np.float32) / 255.0\n",
    "        except:\n",
    "            img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.float32)\n",
    "\n",
    "        # Standard ExG\n",
    "        r, g, b = img[:,:,0], img[:,:,1], img[:,:,2]\n",
    "        exg = (2 * g) - r - b\n",
    "        exg = (exg - exg.min()) / (exg.max() - exg.min() + 1e-6)\n",
    "        \n",
    "        img_4c = np.dstack((img, exg))\n",
    "        image = torch.tensor(img_4c.transpose(2, 0, 1), dtype=torch.float32)\n",
    "        \n",
    "        if not self.is_test:\n",
    "            if np.random.random() > 0.5: image = torch.flip(image, dims=[2])\n",
    "            if np.random.random() > 0.5: image = torch.flip(image, dims=[1])\n",
    "\n",
    "        image = (image - self.mean) / self.std\n",
    "\n",
    "        if self.is_test:\n",
    "            img_id = Path(rel_path).stem \n",
    "            return image, img_id\n",
    "        else:\n",
    "            targets = self.df.loc[idx, self.target_cols].values.astype(float)\n",
    "            targets = np.log1p(targets) \n",
    "            return image, torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL FACTORY\n",
    "# ==========================================\n",
    "def load_weights_safely(model, alias):\n",
    "    weights_path = None\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            if alias in filename and '.pth' in filename:\n",
    "                weights_path = os.path.join(dirname, filename)\n",
    "                break\n",
    "        if weights_path: break\n",
    "    \n",
    "    if weights_path:\n",
    "        try: model.load_state_dict(torch.load(weights_path, weights_only=False))\n",
    "        except: pass\n",
    "        print(f\"Loaded {alias} weights.\")\n",
    "    else:\n",
    "        print(f\"Warning: {alias} weights not found. Training from scratch (Performance Risk).\")\n",
    "\n",
    "def get_resnet34():\n",
    "    model = models.resnet34(weights=None)\n",
    "    load_weights_safely(model, 'resnet34')\n",
    "    original_conv1 = model.conv1\n",
    "    model.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    with torch.no_grad():\n",
    "        model.conv1.weight[:, :3, :, :] = original_conv1.weight\n",
    "        model.conv1.weight[:, 3:4, :, :] = torch.mean(original_conv1.weight, dim=1, keepdim=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 5)\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def get_densenet121():\n",
    "    model = models.densenet121(weights=None)\n",
    "    load_weights_safely(model, 'densenet121')\n",
    "    original_conv0 = model.features.conv0\n",
    "    model.features.conv0 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    with torch.no_grad():\n",
    "        model.features.conv0.weight[:, :3, :, :] = original_conv0.weight\n",
    "        model.features.conv0.weight[:, 3:4, :, :] = torch.mean(original_conv0.weight, dim=1, keepdim=True)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, 5)\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING ENGINE (With MixUp)\n",
    "# ==========================================\n",
    "class WeightedHuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.huber = nn.HuberLoss(reduction='none', delta=delta)\n",
    "        self.weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]).to(DEVICE)\n",
    "    def forward(self, preds, targets):\n",
    "        return (self.huber(preds, targets) * self.weights).mean()\n",
    "\n",
    "def train_model(model_name, splits, train_pivot):\n",
    "    print(f\"\\n--- Training {model_name} with MixUp ---\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(splits):\n",
    "        print(f\"Fold {fold+1}/{N_FOLDS}\")\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            Biomass4ChannelDataset(train_pivot.iloc[train_idx], TARGET_COLS),\n",
    "            batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            Biomass4ChannelDataset(train_pivot.iloc[val_idx], TARGET_COLS),\n",
    "            batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",
    "        )\n",
    "        \n",
    "        if model_name == 'resnet34': model = get_resnet34()\n",
    "        else: model = get_densenet121()\n",
    "            \n",
    "        criterion = WeightedHuberLoss(delta=1.0)\n",
    "        optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train()\n",
    "            for x, y in train_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # --- MIXUP LOGIC (The Winning Formula) ---\n",
    "                if np.random.random() < 0.5:\n",
    "                    lam = np.random.beta(1.0, 1.0)\n",
    "                    index = torch.randperm(x.size(0)).to(DEVICE)\n",
    "                    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "                    \n",
    "                    # Unlog -> Mix -> Relog\n",
    "                    y_lin_a = torch.expm1(y)\n",
    "                    y_lin_b = torch.expm1(y[index])\n",
    "                    mixed_y = torch.log1p(lam * y_lin_a + (1 - lam) * y_lin_b)\n",
    "                    \n",
    "                    preds = model(mixed_x)\n",
    "                    loss = criterion(preds, mixed_y)\n",
    "                else:\n",
    "                    preds = model(x)\n",
    "                    loss = criterion(preds, y)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for x, y in valid_loader:\n",
    "                    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                    val_loss += criterion(model(x), y).item()\n",
    "            \n",
    "            avg_val = val_loss / len(valid_loader)\n",
    "            scheduler.step()\n",
    "            \n",
    "            if avg_val < best_loss:\n",
    "                best_loss = avg_val\n",
    "                torch.save(model.state_dict(), f\"{model_name}_fold{fold}.pth\")\n",
    "        \n",
    "        print(f\"  Best Loss: {best_loss:.4f}\")\n",
    "        del model, optimizer, train_loader, valid_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# ==========================================\n",
    "# 5. EXECUTION\n",
    "# ==========================================\n",
    "raw_df = pd.read_csv(\"/kaggle/input/csiro-biomass/train.csv\")\n",
    "train_pivot = raw_df.pivot(index='image_path', columns='target_name', values='target').reset_index().fillna(0.0)\n",
    "train_pivot['bin'] = pd.qcut(train_pivot['Dry_Total_g'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "splits = list(skf.split(train_pivot, train_pivot['bin']))\n",
    "\n",
    "# TRAIN BOTH (This will take ~4-5 hours)\n",
    "train_model('resnet34', splits, train_pivot)\n",
    "train_model('densenet121', splits, train_pivot)\n",
    "\n",
    "# ==========================================\n",
    "# 6. ENSEMBLE INFERENCE\n",
    "# ==========================================\n",
    "print(\"\\nStarting Ensemble Inference...\")\n",
    "test_df_raw = pd.read_csv(\"/kaggle/input/csiro-biomass/test.csv\")\n",
    "test_unique = test_df_raw[['image_path']].drop_duplicates()\n",
    "test_ds = Biomass4ChannelDataset(test_unique, is_test=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "final_preds_accum = {}\n",
    "models_to_run = ['resnet34', 'densenet121']\n",
    "\n",
    "for model_name in models_to_run:\n",
    "    for fold in range(N_FOLDS):\n",
    "        print(f\"Predicting {model_name} Fold {fold+1}...\")\n",
    "        \n",
    "        if model_name == 'resnet34': model = get_resnet34()\n",
    "        else: model = get_densenet121()\n",
    "            \n",
    "        model.load_state_dict(torch.load(f\"{model_name}_fold{fold}.pth\", weights_only=True))\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, img_ids in test_loader:\n",
    "                images = images.to(DEVICE)\n",
    "                \n",
    "                # TTA: 3 Views (Normal + Flip H + Flip V)\n",
    "                # This ensures maximum coverage\n",
    "                p1 = model(images)\n",
    "                p2 = model(torch.flip(images, dims=[3]))\n",
    "                p3 = model(torch.flip(images, dims=[2]))\n",
    "                \n",
    "                avg_log = (p1 + p2 + p3) / 3.0\n",
    "                preds = np.expm1(avg_log.cpu().numpy())\n",
    "                \n",
    "                for i, img_id in enumerate(img_ids):\n",
    "                    if img_id not in final_preds_accum: final_preds_accum[img_id] = np.zeros(5)\n",
    "                    final_preds_accum[img_id] += preds[i]\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Average across (2 models * 5 folds * 3 TTA = 30 votes per image!)\n",
    "results = []\n",
    "divisor = len(models_to_run) * N_FOLDS\n",
    "\n",
    "for img_id, total_preds in final_preds_accum.items():\n",
    "    avg_pred = total_preds / divisor\n",
    "    for j, col in enumerate(TARGET_COLS):\n",
    "        results.append({'sample_id': f\"{img_id}__{col}\", 'target': float(avg_pred[j])})\n",
    "\n",
    "submission_df = pd.DataFrame(results)\n",
    "submission_df['target'] = submission_df['target'].clip(lower=0.0)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Dual-MixUp Ensemble Submission Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6b94bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T00:00:25.584875Z",
     "iopub.status.busy": "2026-01-06T00:00:25.584540Z",
     "iopub.status.idle": "2026-01-06T00:00:25.604144Z",
     "shell.execute_reply": "2026-01-06T00:00:25.603390Z"
    },
    "papermill": {
     "duration": 0.025796,
     "end_time": "2026-01-06T00:00:25.605976",
     "exception": false,
     "start_time": "2026-01-06T00:00:25.580180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1001187975__Dry_Green_g</td>\n",
       "      <td>17.583729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1001187975__Dry_Dead_g</td>\n",
       "      <td>27.121850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1001187975__Dry_Clover_g</td>\n",
       "      <td>0.351697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1001187975__GDM_g</td>\n",
       "      <td>17.067521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1001187975__Dry_Total_g</td>\n",
       "      <td>43.925161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id     target\n",
       "0   ID1001187975__Dry_Green_g  17.583729\n",
       "1    ID1001187975__Dry_Dead_g  27.121850\n",
       "2  ID1001187975__Dry_Clover_g   0.351697\n",
       "3         ID1001187975__GDM_g  17.067521\n",
       "4   ID1001187975__Dry_Total_g  43.925161"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 2847,
     "sourceId": 4958,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6885,
     "sourceId": 9959,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6978,
     "sourceId": 10038,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 23496,
     "sourceId": 30046,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 251095,
     "sourceId": 848739,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 504915,
     "sourceId": 936546,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 931479,
     "sourceId": 1575486,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1019605,
     "sourceId": 1718973,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1308452,
     "sourceId": 2179449,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1529762,
     "sourceId": 2524833,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3884593,
     "sourceId": 6746686,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3930781,
     "sourceId": 6836924,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1698210,
     "sourceId": 2781718,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 19591654,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2154.969258,
   "end_time": "2026-01-06T00:00:28.410344",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-05T23:24:33.441086",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
